---
title: "Predictive Analytics Exam Module 6, Section 7"

---
If you are using R 3.6.0 or later, the following command will ensure that the random number generator being used is the same as in prior versions of R. Because these modules were developed using R 3.5.0, output that depends on random numbers used the older generator. Running this code will have your output match that shown in the modules.


```{r}
# Run this chunk if using R 3.6.0 or later.
RNGkind(sample.kind = "Rounding")
```

If you are using R 4.0.0 or later, the following command will ensure that read.csv() interprets variables whose values are characters as factor variables. This was the default behavior in prior versions of R. All code is written assuming such variables are factor variables.

```{r}
# Run this chunk if using R 4.0.0 or later. You may get what looks like an error message. It can be ignored.
options(stringsAsFactors = TRUE)
```

Run CHUNKS 1-3 to prepare the AutoClaim data for cross validation.

```{r}
# CHUNK 1
# Load data
AutoClaim <- read.csv("AutoClaim.csv")

# Only use cases where the target variable is positive.
data.AC <- AutoClaim[AutoClaim$CLM_AMT5 > 0, ]

# Remove variables we will not use as predictors.
data.AC$POLICYNO <- NULL
data.AC$PLCYDATE <- NULL
data.AC$CLM_FREQ5 <- NULL
data.AC$IN_YY <- NULL
data.AC$CLM_FLAG <- NULL
data.AC$CLM_AMT <- NULL

summary(data.AC)
```

The summary indicates that there are missing values (NA) in the data set. CHUNK 2 counts the number of records with at least one missing value and then removes them.

```{r}
# CHUNK 2

cc <- complete.cases(data.AC)
sum(cc)
data.AC <- data.AC[cc, ]
summary(data.AC)
```

CHUNK 3 uses caret to split the data into training and testing sets. One feature of the approach used is that the split tries to have the two sets produce similar distributions for the target variable. For a continuous variable (as in this case) it is split into intervals based on values of the target and the desired split percentages done within each interval (e.g., stratified sampling). For classification problems the sampling is done for each of the two outcomes separately. See the documentation for more information.

```{r}
# CHUNK 3

library(caret)
set.seed(1000)
training.indices <- createDataPartition(data.AC$CLM_AMT5, p = 0.8, list = FALSE)
data.AC.train <- data.AC[training.indices, ]
data.AC.test <- data.AC[-training.indices, ]
```

Run CHUNK 4 to perform the cross validation.

```{r}
# CHUNK 4
library(glmnet)
# Fit a Gaussian regression model for the log of the claim amounts. Note that glmnet does not allow for link functions. So this is not the same as using a GLM to predict claims using exponentiation of the linear predictor (log link).

# Default values are mostly used. Enter ?cv.glment in the Console to see the defaults.
set.seed(42)
f <- as.formula(paste("CLM_AMT5~", paste(colnames(data.AC)[-1], collapse = "+")))
X <- model.matrix(f, data.AC.train)

m <- cv.glmnet(
  x = X,
  y = log(data.AC.train$CLM_AMT5),
  family = "gaussian",
  alpha = 1
)
```

Run CHUNK 5 to make a plot that relates to the output from running the cross-validation.

```{r}
# CHUNK 5
plot(m)
```

Run CHUNK 6 to fit the model to the full training set, obtain predicted values for the test set, and then determine the mean squared error.

```{r}
# CHUNK 6

m.best <- glmnet(
  x = X,
  y = log(data.AC.train$CLM_AMT5),
  family = "gaussian", lambda = m$lambda.min,
  alpha = 1
)
X.test <- model.matrix(f, data.AC.test)
m.best.predict <- predict(m.best, newx = X.test)
mse <- sum((m.best.predict - log(data.AC.test$CLM_AMT5))^2) / nrow(data.AC.test)
mse
```

Run CHUNK 7 to evaluate five choices for alpha, each time using the best lambda to evaluate the model.

```{r}
# CHUNK 7
# Run a for loop to determine lambda for five alpha values.
lambda.best <- NULL
mse.best <- NULL
mse.test <- NULL
for (i in 0:4) {
  alpha <- i / 4
  set.seed(42) # We reset the seed each time so each CV uses the same partitions.
  m <- cv.glmnet(
    x = X,
    y = log(data.AC.train$CLM_AMT5),
    family = "gaussian",
    alpha = alpha
  )
  m.best <- glmnet(
    x = X,
    y = log(data.AC.train$CLM_AMT5),
    family = "gaussian", lambda = m$lambda.min,
    alpha = alpha
  )
  m.best.predict <- predict(m.best, newx = X)
  mse <- sum((m.best.predict - log(data.AC.train$CLM_AMT5))^2) / nrow(data.AC.train)
  lambda.best <- cbind(lambda.best, m$lambda.min)
  mse.best <- cbind(mse.best, mse)
  m.best.predict <- predict(m.best, newx = X.test)
  mse <- sum((m.best.predict - log(data.AC.test$CLM_AMT5))^2) / nrow(data.AC.test)
  mse.test <- cbind(mse.test, mse)
}
lambda.best
mse.best
mse.test
```
